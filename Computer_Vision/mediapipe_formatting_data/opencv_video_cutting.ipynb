{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extracting the hand coordinates: \n",
    "###### https://arkalsekar.medium.com/how-to-get-all-the-co-ordinates-of-hand-using-mediapipe-hand-solutions-ac7e2742f702\n",
    "###### https://www.futurelearn.com/info/courses/introduction-to-image-analysis-for-plant-phenotyping/0/steps/305359\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 14:53:07.373062: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-20 14:53:07.424253: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-20 14:53:07.425684: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-20 14:53:08.297261: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/violet/Programs/miniconda3/envs/ai_hackathon/lib/python3.9/site-packages/cv2/qt/plugins\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<enumerate object at 0x7fa6706b4600>\n",
      "<enumerate object at 0x7fa6706b4600>\n",
      "<enumerate object at 0x7fa670470640>\n",
      "<enumerate object at 0x7fa66815fbc0>\n",
      "<enumerate object at 0x7fa670470e00>\n",
      "<enumerate object at 0x7fa670470e00>\n",
      "<enumerate object at 0x7fa670470e00>\n",
      "<enumerate object at 0x7fa668164580>\n",
      "<enumerate object at 0x7fa6681649c0>\n",
      "<enumerate object at 0x7fa6681649c0>\n",
      "<enumerate object at 0x7fa6681649c0>\n",
      "<enumerate object at 0x7fa6681646c0>\n",
      "<enumerate object at 0x7fa6681646c0>\n",
      "<enumerate object at 0x7fa6681646c0>\n",
      "<enumerate object at 0x7fa6681646c0>\n",
      "<enumerate object at 0x7fa679c7e640>\n",
      "<enumerate object at 0x7fa679c7e640>\n",
      "<enumerate object at 0x7fa679c7e640>\n",
      "<enumerate object at 0x7fa679c7e640>\n",
      "<enumerate object at 0x7fa679c7e640>\n",
      "<enumerate object at 0x7fa670bebcc0>\n",
      "<enumerate object at 0x7fa670bebcc0>\n",
      "<enumerate object at 0x7fa670bebcc0>\n",
      "<enumerate object at 0x7fa670bebcc0>\n",
      "<enumerate object at 0x7fa670bebcc0>\n",
      "<enumerate object at 0x7fa670bebcc0>\n",
      "<enumerate object at 0x7fa670bebcc0>\n",
      "<enumerate object at 0x7fa670bebcc0>\n",
      "<enumerate object at 0x7fa670bebcc0>\n",
      "<enumerate object at 0x7fa670bebcc0>\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "  while cap.isOpened():\n",
    "    \n",
    "    \n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # Flip the image horizontally for a later selfie-view display, and convert\n",
    "    # the BGR image to RGB.\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    results = hands.process(image)\n",
    "    image_height, image_width, _ = image.shape\n",
    "    # Draw the hand annotations on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "      for hand_landmarks in results.multi_hand_landmarks:\n",
    "        # Here is How to Get All the Coordinates\n",
    "        for ids, landmrk in enumerate(hand_landmarks.landmark):\n",
    "            # print(ids, landmrk)\n",
    "            cx, cy = landmrk.x * image_width, landmrk.y*image_height\n",
    "            # print(cx, cy)\n",
    "        print(enumerate(hand_landmarks.landmark))            # print (ids, cx, cy)\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "    cv2.imshow('MediaPipe Hands', image)\n",
    "\n",
    "    #stop the process\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'): \n",
    "        break\n",
    "# After the loop release the cap object \n",
    "cap.release() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b560c0>\n",
      "<enumerate object at 0x7fa670b56200>\n",
      "<enumerate object at 0x7fa670b56200>\n",
      "<enumerate object at 0x7fa670b56200>\n",
      "<enumerate object at 0x7fa670b56200>\n",
      "<enumerate object at 0x7fa670b56200>\n",
      "<enumerate object at 0x7fa670414440>\n",
      "<enumerate object at 0x7fa670414440>\n",
      "<enumerate object at 0x7fa670414440>\n",
      "<enumerate object at 0x7fa670414440>\n",
      "<enumerate object at 0x7fa670414440>\n",
      "<enumerate object at 0x7fa670414440>\n",
      "<enumerate object at 0x7fa670414440>\n",
      "<enumerate object at 0x7fa670414440>\n",
      "<enumerate object at 0x7fa670414440>\n",
      "<enumerate object at 0x7fa670414440>\n",
      "<enumerate object at 0x7fa670414440>\n",
      "<enumerate object at 0x7fa670414440>\n",
      "<enumerate object at 0x7fa670414440>\n",
      "<enumerate object at 0x7fa670414440>\n",
      "<enumerate object at 0x7fa670414440>\n",
      "<enumerate object at 0x7fa670414440>\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "  while cap.isOpened():\n",
    "    \n",
    "    \n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # Flip the image horizontally for a later selfie-view display, and convert\n",
    "    # the BGR image to RGB.\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    results = hands.process(image)\n",
    "    image_height, image_width, _ = image.shape\n",
    "    # Draw the hand annotations on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "      for hand_landmarks in results.multi_hand_landmarks:\n",
    "        # Here is How to Get All the Coordinates\n",
    "        for ids, landmrk in enumerate(hand_landmarks.landmark):\n",
    "            # print(ids, landmrk)\n",
    "            cx, cy = landmrk.x * image_width, landmrk.y*image_height\n",
    "            # print(cx, cy)\n",
    "        print(enumerate(hand_landmarks.landmark))            # print (ids, cx, cy)\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "    cv2.imshow('MediaPipe Hands', image)\n",
    "\n",
    "    #stop the process\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'): \n",
    "        break\n",
    "# After the loop release the cap object \n",
    "cap.release() \n",
    "\n",
    "#closes all instance of the camera\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the opencv library \n",
    "import cv2 \n",
    "  \n",
    "  \n",
    "# define a video capture object \n",
    "vid = cv2.VideoCapture(0) \n",
    "  \n",
    "while(True): \n",
    "      \n",
    "    # Capture the video frame \n",
    "    # by frame \n",
    "    ret, frame = vid.read() \n",
    "  \n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('frame', frame) \n",
    "\n",
    "    #extracting the frames  \n",
    "    \n",
    "    \n",
    "\n",
    "    # the 'q' button is set as the \n",
    "    # quitting button you may use any \n",
    "    # desired button of your choice \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object \n",
    "vid.release() \n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
